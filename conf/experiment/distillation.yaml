# @package _global_
defaults:
  - override /train/data: distillation
  - override /train/model: spynet

train:
  ddp: False
  teacher:
    name: "flowformer"
    ckpt: "kitti"
    input_size: [ 120, 160 ]

  refiner:
    _target_: core.modules.conv.IterativeRefinement
    mid_ch: 64
    blocks: 3
    steps: 5

  refiner_ckpt: "/home/aghinassi/Desktop/checkpoints/cleaner.ckpt"

  optimizer:
    lr: 1e-4
    betas: [ 0.9, 0.99 ]

  scheduler:
    eta_min: 1e-5

  optimizer_r:
    _target_: torch.optim.Adam
    lr: 1e-5
    betas: [ 0.9, 0.999 ]
    eps: 1e-08
    weight_decay: 0

  scheduler_r:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: ${train.max_epochs}
    eta_min: 1e-7
    verbose: False